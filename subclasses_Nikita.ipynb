{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from fake_useragent import UserAgent\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON, XML\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import bookquery\n",
    "import os\n",
    "import io\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from os.path import join,isfile\n",
    "from os import listdir\n",
    "from collections import Counter\n",
    "import dask\n",
    "import openpyxl\n",
    "from SPARQLExecutor import SPARQLExecutor\n",
    "\n",
    "basic_dir = \"example\"\n",
    "\n",
    "def counter_for_files(path):\n",
    "    \n",
    "    \"\"\"Подсчет файлов в директории\"\"\"\n",
    "        \n",
    "    onlyfiles = [join(path, f) for f in listdir(path) if isfile(join(path, f))]\n",
    "    return onlyfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ua = UserAgent()\n",
    "bad_requests = []\n",
    "\n",
    "def execute_query(qquery, entity_id):\n",
    "    \n",
    "    \"\"\"Базовая функция для связи с сервером\"\"\"\n",
    "    \n",
    "    sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\", agent = ua.random)\n",
    "    sparql.setQuery(qquery.format(entity_id = entity_id))\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "    return results['results']['bindings']\n",
    "\n",
    "def entities_sparqul(entity_id, f = 0):\n",
    "    \n",
    "    \"\"\"Получение ответа с сервера и формирование датафреймов\"\"\"\n",
    "    \n",
    "    res = []\n",
    "    if f > 5:\n",
    "        global bad_requests\n",
    "        bad_requests.append(entity_id)\n",
    "        print('Bad request ', entity_id)\n",
    "        return None\n",
    "    try:\n",
    "        results= execute_query(bookquery.subclass_with_parents, entity_id)\n",
    "        for result in results:\n",
    "            entities = {}\n",
    "            entities['subclass'] = result['show']['value'].split('/')[-1]\n",
    "            entities['subclasslabel'] = result['showLabel']['value']\n",
    "            entities['classid'] = result['parent']['value'].split('/')[-1]\n",
    "            entities['classlabel'] = result['parentLabel']['value']\n",
    "            res.append(entities)\n",
    "        return pd.DataFrame(data = res, columns = ['classid', 'classlabel' ,'subclass', 'subclasslabel'])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        time.sleep(5)\n",
    "        print('Try again ', entity_id, f)\n",
    "        return entities_sparqul(entity_id, f + 1)\n",
    "    \n",
    "def new_sheets(sheetname , ID , filename):\n",
    "    \n",
    "    \"\"\"Функция формирования листов excel\"\"\"\n",
    "    \n",
    "#     print(sheetname , filename)\n",
    "    if len(sheetname)>30:\n",
    "        sheetname = sheetname[:30]\n",
    "    df = entities_sparqul(ID)\n",
    "    df = df[df['classid'].isin(list(df.subclass))] # Очищаем от классов без родителей\n",
    "    df =  df[lambda x : x['subclasslabel'].str[0]!='Q']# Убираем все Q\n",
    "    local_lst = []\n",
    "#     for k,v in df.iterrows():# В цикле чистим все повторяющиеся классы и их подклассы\n",
    "#         if (((v.classid in all_id) or (v.classid in local_lst)) and (v.classid != ID)) or (v.subclass in all_id):\n",
    "#             local_lst.append(v.subclass)\n",
    "#             df.drop(k,inplace = True)\n",
    "    if len(df) == 0:\n",
    "        return\n",
    "    new_df = df.groupby(['subclass' , 'subclasslabel']).apply(\n",
    "        lambda x: ','.join(list(map(lambda x: '_'.join(x) , zip(x.classid,x.classlabel))))).reset_index()# Формируем столбец классов\n",
    "    new_df.columns = ['subclass' , 'subclasslabel' , 'class']\n",
    "    if sheetname == filename or f\"{filename}\" not in list(map(lambda x: x.split(\"\\\\\")[1].split('.')[0] , counter_for_files(f\"{basic_dir}/basic\"))):\n",
    "        new_df.to_excel(f'{basic_dir}/basic/{filename}.xlsx', sheet_name = sheetname ,encoding='utf-8-sig' , index = False)\n",
    "    else:\n",
    "        with pd.ExcelWriter(f'{basic_dir}/basic/{filename}.xlsx' ,  engine=\"openpyxl\" , mode  = 'a') as writer:\n",
    "            new_df.to_excel(writer, sheet_name = sheetname , encoding='utf-8-sig' , index = False)\n",
    "\n",
    "def new_file(name , dic):\n",
    "    \n",
    "    \"\"\"Функция формирования файлов\"\"\"\n",
    "    \n",
    "    if f'{name}' not in list(map(lambda x: x.split(\"\\\\\")[1].split('.')[0] , counter_for_files(f\"{basic_dir}/basic\"))):\n",
    "        for k,v in dic.items():\n",
    "            if k == name:\n",
    "                new_sheets(k,v , name)\n",
    "                del(dic[k])\n",
    "                break\n",
    "        for k,v in dic.items():\n",
    "            new_sheets(k,v , name)   \n",
    "            \n",
    "def normalization(name , lst):\n",
    "    executor = SPARQLExecutor()\n",
    "    labels = executor.execute(bookquery.labels , qid=' '.join(f'wd:{qid}' for qid in lst))\n",
    "    new_dic = {item['qidLabel']:item['qid'].split('/')[-1] for item in labels}\n",
    "    return (name , new_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entities_sparqul_count(entity_id, f = 0):\n",
    "    \n",
    "    \"\"\"Функция обработчик для файла с количеством представителей\"\"\"\n",
    "    \n",
    "    res = []\n",
    "    if f > 5:\n",
    "        global bad_requests\n",
    "        bad_requests.append(entity_id)\n",
    "        print('Bad request ', entity_id)\n",
    "        return None\n",
    "    try:\n",
    "        entities = {}\n",
    "        raw_results= execute_query(bookquery.subclass_entity_count, entity_id)\n",
    "        entities['subclass'] = entity_id\n",
    "        entities['count_P31'] = int(raw_results[0]['entitycount']['value'])\n",
    "        res.append(entities)\n",
    "        return pd.DataFrame(data = res, columns = ['subclass', 'count_P31'])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        time.sleep(5)\n",
    "        print('Try again ', entity_id, f)\n",
    "        return entities_sparqul_count(entity_id, f + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def creating_file(file):\n",
    "    \n",
    "    \"\"\"Файлы с представителями\"\"\"\n",
    "    \n",
    "    filename = file.split('\\\\')[1].split('.')[0]\n",
    "    if f\"{filename}_with_count\" in list(map(lambda x: x.split('\\\\')[1].split('.')[0] , counter_for_files(f\"{basic_dir}/with_count\"))):\n",
    "        return\n",
    "    xl = pd.ExcelFile(file)\n",
    "    for i in range(len(xl.sheet_names)):\n",
    "        res = []\n",
    "        df = xl.parse(xl.sheet_names[i])\n",
    "        for ID in df['subclass']:\n",
    "            res.append(dask.delayed(entities_sparqul_count)(ID))\n",
    "        result = dask.compute(*res)\n",
    "        final_result = pd.concat(result)\n",
    "        final_result = df.join(final_result.set_index('subclass'), on='subclass').sort_values(\n",
    "            by = 'count_P31' ,ascending = False)\n",
    "        if i==0:\n",
    "            final_result.to_excel(f'{basic_dir}/with_count/{filename}_with_count.xlsx', sheet_name = xl.sheet_names[i] ,encoding='utf-8-sig' , index = False)\n",
    "        else:\n",
    "            with pd.ExcelWriter(f'{basic_dir}/with_count/{filename}_with_count.xlsx' ,  engine=\"openpyxl\" , mode  = 'a') as writer:\n",
    "                final_result.to_excel(writer, sheet_name = xl.sheet_names[i] , encoding='utf-8-sig' , index = False)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def without_zeros(file):\n",
    "    \n",
    "    \"\"\"Удаление нулей\"\"\"\n",
    "    \n",
    "    filename = file.split('\\\\')[1].split('.')[0]\n",
    "    if f\"{filename}_without_zeros\" in list(map(lambda x: x.split('\\\\')[1].split('.')[0] , counter_for_files(f\"{basic_dir}/without_zeros\"))):\n",
    "        return\n",
    "    xl = pd.ExcelFile(file)\n",
    "    for i in range(len(xl.sheet_names)):\n",
    "        res = []\n",
    "        df = xl.parse(xl.sheet_names[i])\n",
    "        df = df[df[\"count_P31\"]>0]\n",
    "        if len(df)==0:\n",
    "            continue\n",
    "        df['signifance'] = \"\"#Добавляем поле для проверки\n",
    "        df = df[['subclass' , 'subclasslabel' , 'class' , 'signifance']]\n",
    "        if i==0:\n",
    "            df.to_excel(f'{basic_dir}/without_zeros/{filename}_without_zeros.xlsx', sheet_name = xl.sheet_names[i] ,encoding='utf-8-sig' , index = False)\n",
    "        else:\n",
    "            with pd.ExcelWriter(f'{basic_dir}/without_zeros/{filename}_without_zeros.xlsx' ,  engine=\"openpyxl\" , mode  = 'a') as writer:\n",
    "                df.to_excel(writer, sheet_name = xl.sheet_names[i] , encoding='utf-8-sig' , index = False)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "arr.append(normalization(\"event\" , [\"Q198\" , \"Q10931\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('event', {'война': 'Q198', 'революция': 'Q10931'})]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Формирование первичных файлов\n",
    "res = []\n",
    "for item in tqdm(arr): \n",
    "    print(item[1] , item[0])\n",
    "    res.append(dask.delayed(new_file)(item[0] , item[1]))\n",
    "result = dask.compute(*res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "#Формирование файла с подсчетом представителей\n",
    "for file in tqdm(counter_for_files(f\"{basic_dir}/basic\")):\n",
    "    creating_file(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Финальный этап формирования\n",
    "res = []\n",
    "for file in tqdm(counter_for_files(f\"{basic_dir}/with_count\")):\n",
    "    res.append(dask.delayed(without_zeros)(file))\n",
    "result = dask.compute(*res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
