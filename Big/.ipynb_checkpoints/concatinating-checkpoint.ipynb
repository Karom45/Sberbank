{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Директория C:\\Users\\Алексей Кушнер\\Sberbank\\Geography\\Big\\Information уже создана\n"
     ]
    }
   ],
   "source": [
    "from fake_useragent import UserAgent\n",
    "from os.path import join,isfile\n",
    "from os import listdir\n",
    "import dask\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import bookquery\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "ua = UserAgent()#Прокси\n",
    "curr_directory = os.getcwd()\n",
    "new_path = join(curr_directory,\"Information\")\n",
    "try:# Создаем базовую директорию для файлов\n",
    "    os.mkdir(new_path)\n",
    "except OSError:\n",
    "    print (\"Директория %s уже создана\" % new_path)\n",
    "    \n",
    "def execute_query(qquery, entity_id):\n",
    "    \n",
    "    \"\"\"Работа с запросами\"\"\"\n",
    "    \n",
    "    sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\",agent = ua.random)\n",
    "    sparql.setQuery(qquery.format(entity_id = entity_id))\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "    return results['results']['bindings']\n",
    "\n",
    "def counter_for_files(path):\n",
    "    \n",
    "    \"\"\"Подсчет файлов в директории\"\"\"\n",
    "    \n",
    "    onlyfiles = [join(path, f) for f in listdir(path) if isfile(join(path, f))]\n",
    "    return onlyfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = []\n",
    "length = 0\n",
    "path.append((join(os.getcwd() , r'pool\\2\\data\\data_with_popularity'),'popularity'))\n",
    "path.append((join(os.getcwd() , r'pool\\2\\analyzing'),'entity_id'))\n",
    "path.append((join(os.getcwd() , r'pool\\2\\analyzing\\aggregated') , 'prop_count'))\n",
    "def concat_sets(path , stat):\n",
    "    \n",
    "    \"\"\"Группировка файлов\"\"\"\n",
    "    \n",
    "    global length\n",
    "    df  =[]\n",
    "    for i in counter_for_files(path):\n",
    "        part_df = pd.read_csv(i, encoding='utf8',sep = ';')\n",
    "        df.append(part_df)\n",
    "    df = pd.concat(df)\n",
    "    if stat =='popularity':\n",
    "        length = len(df)\n",
    "    name = counter_for_files(path)[0].split(f'\\\\')[-1].split('.')[0].split('_')[:-1]\n",
    "    name = '_'.join(name)\n",
    "    if stat == 'prop_count':\n",
    "        df = df.groupby('prop_name').sum().sort_values(by = stat,ascending = False)\n",
    "        df['prop_counter'] = ( df['prop_count'] / length)*100\n",
    "        df.to_csv(f'{path}\\\\{name}.csv' , encoding='utf-8-sig',sep = ';')\n",
    "    else:\n",
    "        df.sort_values(by = stat,ascending = False).to_csv(f'{path}\\\\{name}.csv' ,\n",
    "                                                           encoding='utf-8-sig',sep = ';' , index = False)\n",
    "    \n",
    "for i in path:\n",
    "    concat_sets(i[0] , i[1])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Блок формирования файла, агрегировнного по предикатам \n",
    "\n",
    "new_path = join(os.getcwd(),r'pool\\2\\data\\data_with_popularity')\n",
    "new_path_stats= join(os.getcwd(),r'pool\\2\\analyzing')\n",
    "new_path_aggregated = join(os.getcwd(),r'pool\\2\\analyzing\\aggregated_with_popularity')\n",
    "def finding_popular(most_popular):\n",
    "    \n",
    "    \"\"\"Обработка 5% наиболее популярных сущностей\"\"\"\n",
    "    \n",
    "    if len(most_popular) * 0.05 < 10:\n",
    "        return list(most_popular.iloc[:10].entity)\n",
    "    elif len(most_popular) * 0.05 >= 100:\n",
    "        return list(most_popular.iloc[:100].entity)\n",
    "    else:\n",
    "        return list(most_popular.iloc[:int(len(most_popular) * 0.05)].entity)\n",
    "    \n",
    "stats_df = pd.read_csv(counter_for_files(new_path_stats)[0],encoding='utf8',sep=';')    \n",
    "most_popular = pd.read_csv(counter_for_files(new_path)[0],encoding='utf8',sep=';')\n",
    "most_popular = finding_popular(most_popular)\n",
    "def filter_func(x):\n",
    "    return x['entity_id'].max() in most_popular\n",
    "        #Топ 5% популярных сущностей\n",
    "name = counter_for_files(new_path)[0].split(f'\\\\')[-1].split('.')[0].split('_')[:-2]\n",
    "name = '_'.join(name)\n",
    "popular_stats = stats_df.groupby('entity_id').filter(filter_func).groupby('prop_name').sum().sort_values(by = ['prop_count','prop_count_value'],ascending = False)\n",
    "popular_stats['prop_counter'] = popular_stats['prop_count']\n",
    "popular_stats.to_csv(join(new_path_aggregated,  f'{name}_aggregated_with_popularity.csv'), encoding='utf-8-sig',sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
