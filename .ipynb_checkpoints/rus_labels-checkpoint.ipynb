{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Директория C:\\Users\\Алексей Кушнер\\Sberbank\\Geography\\Information уже создана\n"
     ]
    }
   ],
   "source": [
    "from fake_useragent import UserAgent\n",
    "from os.path import join,isfile\n",
    "from os import listdir\n",
    "import dask\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import bookquery\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "ua = UserAgent()#Прокси\n",
    "curr_directory = os.getcwd()\n",
    "new_path = join(curr_directory,\"Information\")\n",
    "try:# Создаем базовую директорию для файлов\n",
    "    os.mkdir(new_path)\n",
    "except OSError:\n",
    "    print (\"Директория %s уже создана\" % new_path)\n",
    "    \n",
    "def execute_query(qquery, entity_id):\n",
    "    \n",
    "    \"\"\"Работа с запросами\"\"\"\n",
    "    \n",
    "    sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\",agent = ua.random)\n",
    "    sparql.setQuery(qquery.format(entity_id = entity_id))\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "    return results['results']['bindings']\n",
    "\n",
    "def counter_for_files(path):\n",
    "    \n",
    "    \"\"\"Подсчет файлов в директории\"\"\"\n",
    "    \n",
    "    onlyfiles = [join(path, f) for f in listdir(path) if isfile(join(path, f))]\n",
    "    return onlyfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл entities_aerodrome_Q62447.csv уже обработана\n",
      "Файл entities_airport_Q1248784.csv уже обработана\n",
      "Файл entities_archipelago_Q33837.csv уже обработана\n",
      "Файл entities_autonomous oblast of Russia_Q309166.csv уже обработана\n",
      "Файл entities_autonomous okrug of Russia_Q184122.csv уже обработана\n",
      "Файл entities_bay_Q39594.csv уже обработана\n",
      "Файл entities_bridge_Q12280.csv уже обработана\n",
      "Файл entities_canal_Q12284.csv уже обработана\n",
      "Файл entities_canyon_Q150784.csv уже обработана\n",
      "Файл entities_cape_Q185113.csv уже обработана\n",
      "Файл entities_cave_Q35509.csv уже обработана\n",
      "Файл entities_channel_Q1210950.csv уже обработана\n",
      "Файл entities_city of the United States_Q1093829.csv уже обработана\n",
      "Файл entities_city town_Q7930989.csv уже обработана\n",
      "Файл entities_city_Q515.csv уже обработана\n",
      "Файл entities_constituent part of the United Kingdom_Q3336843.csv уже обработана\n",
      "Файл entities_continental area and surrounding islands_Q2418896.csv уже обработана\n",
      "Файл entities_continent_Q5107.csv уже обработана\n",
      "Файл entities_country_Q6256.csv уже обработана\n",
      "Файл entities_crater_Q3240715.csv уже обработана\n",
      "Файл entities_desert_Q8514.csv уже обработана\n",
      "Файл entities_drainage basin_Q166620.csv уже обработана\n",
      "Файл entities_federal city of Russia_Q183342.csv уже обработана\n",
      "Файл entities_fjard_Q319714.csv уже обработана\n",
      "Файл entities_fjord_Q45776.csv уже обработана\n",
      "Файл entities_forest_Q4421.csv уже обработана\n",
      "Файл entities_fountain_Q483453.csv уже обработана\n",
      "Файл entities_geographic region_Q82794.csv уже обработана\n",
      "Файл entities_geographical pole_Q183273.csv уже обработана\n",
      "Файл entities_geyser_Q83471.csv уже обработана\n",
      "Файл entities_glacier_Q35666.csv уже обработана\n",
      "Файл entities_gracht_Q523166.csv уже обработана\n",
      "Файл entities_group of lakes_Q5926864.csv уже обработана\n",
      "Файл entities_hemisphere of the Earth_Q399984.csv уже обработана\n",
      "Файл entities_heritage site_Q358.csv уже обработана\n",
      "Файл entities_historic site_Q1081138.csv уже обработана\n",
      "Файл entities_island group_Q1402592.csv уже обработана\n",
      "Файл entities_island_Q23442.csv начал обрабатываться 21:30:31.921809\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-90ebbbc8c9e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mfile_creation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m \u001b[0mmain_part\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-90ebbbc8c9e2>\u001b[0m in \u001b[0;36mmain_part\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mcurr_path\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Information\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"2\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\\\data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcounter_for_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurr_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mfile_creation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'2'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[0mmain_part\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-90ebbbc8c9e2>\u001b[0m in \u001b[0;36mfile_creation\u001b[1;34m(file, path)\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;31m#Запросы по каждой сущности\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m                 \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'entity'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1066\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1068\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1069\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   4723\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4724\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4725\u001b[1;33m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4726\u001b[0m         \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues_from_object\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4727\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.values_from_object\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_internal_get_values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_internal_get_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    595\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mget_values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m         \u001b[1;34m\"\"\" return a dense type view \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1594\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_block\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1595\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1596\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36m_block\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1521\u001b[0m         \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1523\u001b[1;33m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1524\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1525\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def entities_sparqul(results):\n",
    "    \n",
    "    \"\"\"Обработка запроса\"\"\"\n",
    "    \n",
    "        res = []\n",
    "        for result in results:# Обработка вернувшегося запрсов\n",
    "            entities = {}\n",
    "            entities['entity'] = result['item']['value'].split('/')[-1]\n",
    "            entities['label'] = result['itemLabel']['value']\n",
    "        return entities#Возвращаем Датафрейм и название сущности\n",
    "    \n",
    "def processing(entity_id,label, f = 0 ):\n",
    "    \n",
    "    \"\"\"Обработка полученного запроса\"\"\"\n",
    "    \n",
    "    if f>5:\n",
    "        print(entity_id)\n",
    "        errors +=1\n",
    "        resu = {'entity' : entity_id , 'label' : label}\n",
    "        return resu\n",
    "    try:\n",
    "        raw_results= execute_query(bookquery.rus_names, entity_id)# Запрос\n",
    "        resu = entities_sparqul(raw_results)\n",
    "        return resu\n",
    "    except Exception as e:\n",
    "        time.sleep(3)\n",
    "        return processing(entity_id,label, f+1)\n",
    "        \n",
    "def file_creation(file,path):\n",
    "    \n",
    "    \"\"\"Формирование файла\"\"\"\n",
    "    \n",
    "        file_name = file.split('\\\\')[-1]\n",
    "        start = time.time()\n",
    "        new_path_2 = join(os.getcwd(),join(\"Information\",path + \"\\\\data\\\\rus_labels\"))\n",
    "        if file_name not in list (map(lambda x:x.split('\\\\')[-1],counter_for_files(new_path_2))):#Проверка на наличие файла\n",
    "            print(f'Файл {file_name } начал обрабатываться {datetime.datetime.now().time()}')\n",
    "            df = pd.read_csv(file ,encoding='utf8',sep = ';')\n",
    "            result = []\n",
    "            errors = 0\n",
    "            for k, v in df.iterrows():#Запросы по каждой сущности\n",
    "                result.append(dask.delayed(processing)(v['entity'] , v['label']))\n",
    "            data = list(dask.compute(*result))\n",
    "            results = pd.DataFrame(data = data)\n",
    "            results.to_csv(join(new_path_2 ,file_name),\n",
    "                          encoding='utf-8-sig',index = False,sep = ';')# Формирование\n",
    "            end = time.time()\n",
    "            print(f'Формирование файла {file_name} окончено , заняло {(end-start)/60} минут\\n , ошибок {errors/len(df)*100}')\n",
    "        else :\n",
    "            print(f'Файл {file_name} уже обработана')  \n",
    "        \n",
    "def main_part():\n",
    "    \n",
    "    \"\"\"Основная функция для прохождения по всем файлам директории\"\"\"\n",
    "    curr_path =join(os.getcwd(),join(\"Information\",\"2\" + \"\\\\data\"))\n",
    "    for file in counter_for_files(curr_path):\n",
    "        file_creation(file , '2')\n",
    "        \n",
    "main_part()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл entities_settlement_Q532 начал обрабатываться 09:27:44.444520\n",
      "Файл entities_settlement_Q532_0 начал обрабатываться 09:27:44.778172\n",
      "Формирование файла entities_settlement_Q532_0 окончено , заняло 16.17502841949463 минут\n",
      "\n",
      "Файл entities_settlement_Q532_1 начал обрабатываться 09:43:55.342381\n",
      "Формирование файла entities_settlement_Q532_1 окончено , заняло 17.55528246164322 минут\n",
      "\n",
      "Файл entities_settlement_Q532_2 начал обрабатываться 10:01:28.706206\n",
      "Формирование файла entities_settlement_Q532_2 окончено , заняло 17.446495532989502 минут\n",
      "\n",
      "Файл entities_settlement_Q532_3 начал обрабатываться 10:18:55.558444\n",
      "Формирование файла entities_settlement_Q532_3 окончено , заняло 17.318514422575632 минут\n",
      "\n",
      "Файл entities_settlement_Q532_4 начал обрабатываться 10:36:14.747434\n",
      "Формирование файла entities_settlement_Q532_4 окончено , заняло 17.296521544456482 минут\n",
      "\n",
      "Файл entities_settlement_Q532_5 начал обрабатываться 10:53:32.601224\n",
      "Формирование файла entities_settlement_Q532_5 окончено , заняло 8.792814763387044 минут\n",
      "\n",
      "Формирование файла entities_settlement_Q532 окончено , заняло 94.59594728549321 минут\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def entities_sparqul(results):\n",
    "    \n",
    "    \"\"\"Обработка запроса\"\"\"\n",
    "    \n",
    "        res = []\n",
    "        for result in results:# Обработка вернувшегося запрсов\n",
    "            entities = {}\n",
    "            entities['entity'] = result['item']['value'].split('/')[-1]\n",
    "            entities['label'] = result['itemLabel']['value']\n",
    "        return entities#Возвращаем Датафрейм и название сущности\n",
    "    \n",
    "def processing(entity_id,label, f = 0 ):\n",
    "    \n",
    "    \"\"\"Обработка полученного запроса\"\"\"\n",
    "    \n",
    "    if f>5:\n",
    "        errors +=1\n",
    "        resu = {'entity' : entity_id , 'label' : label}\n",
    "        return resu\n",
    "    try:\n",
    "        raw_results= execute_query(bookquery.rus_names, entity_id)# Запрос\n",
    "        resu = entities_sparqul(raw_results)\n",
    "        return resu\n",
    "    except Exception as e:\n",
    "        time.sleep(3)\n",
    "        return processing(entity_id,label, f+1)\n",
    "        \n",
    "def creating_parts(i, ids, file_name,path):\n",
    "    \n",
    "    \"\"\"Формирование блоков по 50000 представителей\"\"\"\n",
    "    \n",
    "    new_path = join(curr_directory,join(\"Information\",path +\"\\\\data\\\\big\\\\parts\"))\n",
    "    if str(i) not in list(map (lambda x : x.split('_')[-1].split('.')[0],counter_for_files(new_path))):\n",
    "        print(f'Файл {file_name}_{i} начал обрабатываться {datetime.datetime.now().time()}')\n",
    "        start = time.time()\n",
    "        res = []\n",
    "        result = []   \n",
    "        for k, v in ids.iterrows():#Запросы по каждой сущности\n",
    "            result.append(dask.delayed(processing)(v['entity'] , v['label']))\n",
    "        data = list(dask.compute(*result))\n",
    "        results = pd.DataFrame(data = data)\n",
    "        results.to_csv(join(new_path ,f'{file_name}_{i}.csv'),\n",
    "                          encoding='utf-8-sig',index = False,sep = ';')# Формирование\n",
    "        end = time.time()\n",
    "        print(f'Формирование файла {file_name}_{i} окончено , заняло {(end-start)/60} минут\\n')\n",
    "    else:\n",
    "        print(f'{i} файл уже обработан')\n",
    "        \n",
    "        \n",
    "def file_creation(file,path):#Создание файла\n",
    "    \n",
    "     \"\"\"Создает файлов с блоками по  50000 представителей \"\"\"\n",
    "        \n",
    "        BLOCK_SIZE = 50000\n",
    "        file_name = file.split('\\\\')[-1].split('.')[0]\n",
    "        new_path_1 = join(os.getcwd(),join(\"Information\",path + \"\\\\data\\\\big\\\\parts\\\\result\"))\n",
    "        if file_name not in list (map(lambda x:x.split('\\\\')[-1].split('.')[0],counter_for_files(new_path_1))):#Проверка на наличие файла\n",
    "            start = time.time()\n",
    "            print(f'Файл {file_name } начал обрабатываться {datetime.datetime.now().time()}')\n",
    "            ids = pd.read_csv(file ,encoding='utf8',sep = ';')\n",
    "            for i in range(math.ceil(len(ids)/BLOCK_SIZE)):\n",
    "                if (i+1) *BLOCK_SIZE< len(ids):\n",
    "                    creating_parts(i , ids[BLOCK_SIZE * i: BLOCK_SIZE*(i+1)] ,file_name,path)\n",
    "                else:\n",
    "                    creating_parts(i , ids[BLOCK_SIZE * i:],file_name,path)\n",
    "            end = time.time()\n",
    "            print(f'Формирование файла {file_name} окончено , заняло {(end-start)/60} минут\\n')\n",
    "        else :\n",
    "            print(f'Файл {file_name} уже обработана')  \n",
    "        \n",
    "def main_part():\n",
    "    curr_path =join(os.getcwd(),join(\"Information\",\"2\" + \"\\\\data\\\\big\"))\n",
    "    resu = []\n",
    "    for file in counter_for_files(curr_path):\n",
    "        file_creation(file , '2')\n",
    "        \n",
    "main_part()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = join(os.getcwd(),join(\"Information\",\"2\" + \"\\\\data\\\\big\\\\parts\"))\n",
    "final_path = join(os.getcwd(),join(\"Information\",\"2\" + \"\\\\data\\\\big\\\\parts\\\\result\"))\n",
    "def concat_sets(path):\n",
    "    df  =[]\n",
    "    for i in counter_for_files(path):\n",
    "        part_df = pd.read_csv(i, encoding='utf8',sep = ';')\n",
    "        df.append(part_df)\n",
    "    name = counter_for_files(path)[0].split('\\\\')[-1].split('.')[0].split('_')[:-1]\n",
    "    name = '_'.join(name)\n",
    "    df = pd.concat(df)\n",
    "    df.to_csv(f'{final_path}\\\\{name}.csv' , encoding='utf-8-sig',sep = ';' , index = False)\n",
    "concat_sets(path)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
