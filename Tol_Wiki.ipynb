{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import io\n",
    "from collections import Counter\n",
    "from os.path import join,isfile\n",
    "from os import listdir\n",
    "import dask\n",
    "from fake_useragent import UserAgent\n",
    "from SPARQLWrapper import SPARQLWrapper, JSON\n",
    "import pandas as pd\n",
    "import bookquery\n",
    "ua = UserAgent()#Прокси\n",
    "\n",
    "def counter_for_files(path):# Подсчет файлов в директории\n",
    "    onlyfiles = [join(path, f) for f in listdir(path) if isfile(join(path, f))]\n",
    "    return onlyfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_query(qquery, entity_id):# Работа с запросами\n",
    "    sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\",agent = ua.random)\n",
    "    sparql.setQuery(qquery.format(entity_id = entity_id))\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "    return results['results']['bindings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_found = []\n",
    "\n",
    "def find_entity(entity):\n",
    "    path = join(os.getcwd() , r\"Information\\2\\data\\rus_labels\")\n",
    "    res = []\n",
    "    dic = {}\n",
    "    for top, dirs, files in os.walk(path):\n",
    "        for f in files:\n",
    "            file_path = join(path,f)\n",
    "            exl = pd.read_csv(io.open(file_path, encoding='utf-8'), sep = ';', header = 0)\n",
    "            entity_list = exl['entity'].tolist()\n",
    "            if entity in entity_list:\n",
    "                return f.split('_')[-1].split('.')[0], f.split('_')[1]\n",
    "    global not_found\n",
    "    not_found.append(entity)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "all_files = []\n",
    "ones = [\"count_constraint\",\"max_by_area_constraint\",\"max_by_height_constraint\",\"max_by_length_constraint\",\n",
    "\"wash\"]\n",
    "path = join(os.getcwd() , f'verified_files')\n",
    "for top, dirs, files in os.walk(path): #проходимся по всем екселям (интентам)\n",
    "    for f in files:\n",
    "        count_x = 0\n",
    "        intent_name = f.split('.')[0] #имя интента|имя файла\n",
    "        exl = pd.read_excel(os.path.join(top, f)) #ексель блохина\n",
    "        if intent_name not in ones:\n",
    "            old_qid = exl[exl['Сущность #0 найдена правильно'] == 1]['QID #0'] #берем нужный столбец, неисправленное QID\n",
    "            new_qid = exl[exl['Сущность #0 найдена правильно'] == 0]['Правильная сущность #0'] #исправленные QID\n",
    "            print(intent_name + '_0')\n",
    "        else:\n",
    "            old_qid = exl[exl['Сущность #1 найдена правильно'] == 1]['QID #1'] #берем нужный столбец, неисправленное QID\n",
    "            new_qid = exl[exl['Сущность #1 найдена правильно'] == 0]['Правильная сущность #1'] #исправленные QID\n",
    "            print(intent_name + '_1')\n",
    "        qid = old_qid.tolist() + new_qid.tolist()\n",
    "        res = []\n",
    "        result = []\n",
    "        exl_type = pd.read_excel(join(os.getcwd(),f'csv\\Entities.xlsx')) #проверяем является ли сущность типом\n",
    "        qid_type = exl_type[exl_type['subclass_weight'] == 2]['subclass']\n",
    "        for i in qid:\n",
    "            if i != 'x' and i != 'х':\n",
    "                if i in qid_type.tolist(): #проверяем является ли сущность типом если да, сразу в res\n",
    "                    type_lable = exl_type[exl_type['subclass'] == i]['subclass_label'].values[0]\n",
    "                    a = (i, type_lable)\n",
    "                    result.append(a)\n",
    "                else:\n",
    "                    result.append(find_entity(i))\n",
    "            else:\n",
    "                count_x += 1\n",
    "        c = Counter()\n",
    "        for i in result:\n",
    "            c[i] += 1 \n",
    "        all_files.append((c,intent_name, len(exl),count_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "Wall time: 2min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_files = []\n",
    "ones = [\"count_constraint\",\"max_by_area_constraint\",\"max_by_height_constraint\",\"max_by_length_constraint\",\n",
    "\"wash\"]\n",
    "path = join(os.getcwd() , f'verified_files_1')\n",
    "for top, dirs, files in os.walk(path): #проходимся по всем екселям (интентам)\n",
    "    for f in files:\n",
    "        count_x = 0\n",
    "        intent_name = f.split('.')[0] #имя интента|имя файла\n",
    "        exl = pd.read_excel(os.path.join(top, f)) #ексель блохина\n",
    "        if intent_name in ones:\n",
    "            old_qid = exl[exl['Сущность #0 найдена правильно'] == 1]['QID #0'] #берем нужный столбец, неисправленное QID\n",
    "            new_qid = exl[exl['Сущность #0 найдена правильно'] == 0]['Правильная сущность #0'] #исправленные QID\n",
    "            print(0)\n",
    "        else:\n",
    "            old_qid = exl[exl['Сущность #1 найдена правильно'] == 1]['QID #1'] #берем нужный столбец, неисправленное QID\n",
    "            new_qid = exl[exl['Сущность #1 найдена правильно'] == 0]['Правильная сущность #1'] #исправленные QID\n",
    "            print(1)\n",
    "        qid = old_qid.tolist() + new_qid.tolist()\n",
    "        res = []\n",
    "        result = []\n",
    "        exl_type = pd.read_excel(join(os.getcwd(),f'csv\\Entities.xlsx')) #проверяем является ли сущность типом\n",
    "        qid_type = exl_type[exl_type['subclass_weight'] == 2]['subclass']\n",
    "        for i in qid:\n",
    "            if i != 'x' and i != 'х':\n",
    "                if i in qid_type.tolist(): #проверяем является ли сущность типом если да, сразу в res\n",
    "                    type_lable = exl_type[exl_type['subclass'] == i]['subclass_label'].values[0]\n",
    "                    a = (i, type_lable)\n",
    "                    result.append(a)\n",
    "                else:\n",
    "                    result.append(find_entity(i))\n",
    "            else:\n",
    "                count_x += 1\n",
    "        c = Counter()\n",
    "        for i in result:\n",
    "            c[i] += 1 \n",
    "        all_files.append((c,intent_name, len(exl),count_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[306, 363, 358, 290, 261, 305, 349]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# {item[1] : item[3] for item in all_files}\n",
    "# all_files\n",
    "[item[2] for item in all_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_dict = {\"area\" : \"площадь(P2046)\",\n",
    "            \"borders_country\" : \"имеет границы с(P47)\",\n",
    "             \"borders_country_count\" : \"имеет границы с(P47)\",\n",
    "            \"capital\" : \"столица(P36)\",\n",
    "             \"climate\" : \"климат(P2564)\",\n",
    "             \"count\": \"just_labels\", \n",
    "             \"count_constraint\": \"just_labels\",\n",
    "            \"country_by_capital\" : \"является столицей(P1376)\",\n",
    "             \"depth\" : \"глубина(P4511)\",\n",
    "             \"height\":\"высота над уровнем моря(P2044)\",\n",
    "             \"length\" : \"длина(P2043)\",\n",
    "             \"list_rivers\":\"just_labels\",\n",
    "             \"location\" : \"just_labels\",\n",
    "             \"location_constraint\" : \"just_labels\",\n",
    "             \"location_coordinates\" : \"координаты(P625)\",\n",
    "             \"max_by_area\":\"площадь(P2046)\",\n",
    "             \"max_by_area_constraint\" : \"площадь(P2046)\",\n",
    "             \"max_by_depth\":\"глубина(P4511)\",\n",
    "             \"max_by_height\":\"высота над уровнем моря(P2044)\",\n",
    "             \"max_by_height_constraint\" : \"высота над уровнем моря(P2044)\",\n",
    "             \"max_by_length\" : \"длина(P2043)\",\n",
    "             \"max_by_length_constraint\" : \"длина(P2043)\",\n",
    "             \"max_by_population_count\" : \"население(P1082)\",\n",
    "             \"min_by_area\" : \"площадь(P2046)\",\n",
    "             \"political_own\" : \"государство(P17)\",\n",
    "            \"population_count\" : \"население(P1082)\",\n",
    "            \"river_confluence\" : \"впадает в(P403)\" ,\n",
    "            \"river_inflows\": \"приток(P974)\",\n",
    "            \"sight_location\": \"just_labels\" ,\n",
    "            \"wash\": \"на берегу(P206)\"}\n",
    "exl_file = pd.ExcelFile(join(os.getcwd() , f'Final analytics\\\\Analytics.xlsx'))\n",
    "df = exl_file.parse(name_dict[all_files[0][1]])\n",
    "df['global'] = 0\n",
    "count_rows = 0\n",
    "count_xx = 0\n",
    "for items in all_files:\n",
    "    del items[0][None]\n",
    "#     print(items)\n",
    "    qid_list = list(map(lambda x :x[0] , list(items[0].keys())))\n",
    "    for k,v in df.iterrows():\n",
    "        ind = list(df[df.subclass == v.subclass].index)[0]\n",
    "        if v.subclass in qid_list:\n",
    "            df.loc[ind,items[1]] = round(items[0][(v.subclass , v.subclass_label)]/items[2] * 100,2)\n",
    "        else:\n",
    "            df.loc[ind,items[1]] = \"-\"\n",
    "new_row = {'subclass_label' : 'x' , 'subclass' : 'x'}\n",
    "new_row.update({item[1] : round(item[3] * 100 /item[2],2) for item in all_files})\n",
    "df = df.append(pd.DataFrame.from_dict([new_row], orient='columns', dtype=None, columns=None))\n",
    "lst = [\"subclass_label\" , \"subclass\"]\n",
    "lst.extend(list(name_dict.keys()))\n",
    "df[lst].to_excel(r'Final analytics\\new_Analytics.xlsx', sheet_name = 'analysis_by_intents' ,encoding='utf-8-sig' , index = False)\n",
    "\n",
    "df = exl_file.parse(name_dict[all_files[0][1]])\n",
    "df['global'] = 0\n",
    "for items in all_files:\n",
    "    count_rows += items[2]\n",
    "    count_xx+= items[3]\n",
    "#     print(items)\n",
    "    qid_list = list(map(lambda x :x[0] , list(items[0].keys())))\n",
    "    for k,v in df.iterrows():\n",
    "        ind = list(df[df.subclass == v.subclass].index)[0]\n",
    "        if v.subclass in qid_list:\n",
    "            df.loc[ind,'global'] += items[0][(v.subclass , v.subclass_label)]\n",
    "        else:\n",
    "            df.loc[ind,'global'] += 0\n",
    "df['global'] = round((df['global']/count_rows) * 100,2)\n",
    "for k,v in df.iterrows():\n",
    "    if v['global'] == 0:\n",
    "        ind = list(df[df.subclass == v.subclass].index)[0]\n",
    "        df.loc[ind,'global'] = '-'\n",
    "print(count_rows)\n",
    "print(count_xx)\n",
    "new_row = {'subclass_label' : 'x' , 'subclass' : 'x', 'global' :round((count_xx/count_rows) * 100,2)}\n",
    "df = df.append(pd.DataFrame.from_dict([new_row], orient='columns', dtype=None, columns=None))\n",
    "lst = [\"subclass_label\" , \"subclass\" , \"global\"]\n",
    "with pd.ExcelWriter(r'Final analytics\\new_Analytics.xlsx' ,  engine=\"openpyxl\" , mode  = 'a') as writer:\n",
    "    df[lst].to_excel(writer, sheet_name = 'global_analysis' , encoding='utf-8-sig' , index = False)   \n",
    "    \n",
    "for items in all_files:\n",
    "    del items[0][None]\n",
    "    df = exl_file.parse(name_dict[items[1]])\n",
    "#     print(items)\n",
    "    qid_list = list(map(lambda x :x[0] , list(items[0].keys())))\n",
    "    for k,v in df.iterrows():\n",
    "        ind = list(df[df.subclass == v.subclass].index)[0]\n",
    "        if v.subclass in qid_list:\n",
    "            df.loc[ind,'Абсолютное значение'] = items[0][(v.subclass , v.subclass_label)]\n",
    "            df.loc[ind,'Относительное значение , %'] = round(items[0][(v.subclass , v.subclass_label)]/items[2] * 100,2)\n",
    "        else:\n",
    "            df.loc[ind,'Абсолютное значение'] = '-'\n",
    "            df.loc[ind,'Относительное значение , %'] = '-'\n",
    "    new_row = {'subclass_label' : 'x' , 'subclass' : 'x', 'Встречаемость предиката для всех (%)' : '-' ,\n",
    "               'Встречаемость предиката для популярных(%)': '-' , 'Абсолютное значение' : items[3] ,\n",
    "               'Относительное значение , %' : round(items[3]* 100/items[2] , 2) }\n",
    "    df = df.append(pd.DataFrame.from_dict([new_row], orient='columns', dtype=None, columns=None))\n",
    "    for k,v in df.iterrows():\n",
    "        ind = list(df[df.subclass == v.subclass].index)[0]\n",
    "        if v['Абсолютное значение'] == 0:\n",
    "            df.loc[ind,'Абсолютное значение'] = '-'\n",
    "        if v['Относительное значение , %'] == 0:\n",
    "            df.loc[ind,'Относительное значение , %'] = '-'\n",
    "    with pd.ExcelWriter(r'Final analytics\\new_Analytics.xlsx' ,  engine=\"openpyxl\" , mode  = 'a') as writer:\n",
    "        df.to_excel(writer, sheet_name = items[1] , encoding='utf-8-sig' , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:7123: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2232\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "name_dict = {             \"count_constraint\": \"just_labels\",\n",
    "             \"location_constraint\" : \"just_labels\",\n",
    "             \"max_by_area_constraint\" : \"площадь(P2046)\",\n",
    "             \"max_by_height_constraint\" : \"высота над уровнем моря(P2044)\",\n",
    "             \"max_by_length_constraint\" : \"длина(P2043)\",\n",
    "            \"sight_location\": \"just_labels\" ,\n",
    "            \"wash\": \"на берегу(P206)\"}\n",
    "exl_file = pd.ExcelFile(join(os.getcwd() , f'Final analytics\\\\Analytics.xlsx'))\n",
    "df = exl_file.parse(name_dict[all_files[0][1]])\n",
    "df['global'] = 0\n",
    "count_rows = 0\n",
    "count_xx = 0\n",
    "for items in all_files:\n",
    "    del items[0][None]\n",
    "#     print(items)\n",
    "    qid_list = list(map(lambda x :x[0] , list(items[0].keys())))\n",
    "    for k,v in df.iterrows():\n",
    "        ind = list(df[df.subclass == v.subclass].index)[0]\n",
    "        if v.subclass in qid_list:\n",
    "            df.loc[ind,items[1]] = round(items[0][(v.subclass , v.subclass_label)]/items[2] * 100,2)\n",
    "        else:\n",
    "            df.loc[ind,items[1]] = \"-\"\n",
    "new_row = {'subclass_label' : 'x' , 'subclass' : 'x'}\n",
    "new_row.update({item[1] : round(item[3] * 100 /item[2],2) for item in all_files})\n",
    "df = df.append(pd.DataFrame.from_dict([new_row], orient='columns', dtype=None, columns=None))\n",
    "lst = [\"subclass_label\" , \"subclass\"]\n",
    "lst.extend(list(name_dict.keys()))\n",
    "df[lst].to_excel(r'Final analytics\\new_Analytics_1.xlsx', sheet_name = 'analysis_by_intents' ,encoding='utf-8-sig' , index = False)\n",
    "\n",
    "df = exl_file.parse(name_dict[all_files[0][1]])\n",
    "df['global'] = 0\n",
    "for items in all_files:\n",
    "    count_rows += items[2]\n",
    "    count_xx+= items[3]\n",
    "#     print(items)\n",
    "    qid_list = list(map(lambda x :x[0] , list(items[0].keys())))\n",
    "    for k,v in df.iterrows():\n",
    "        ind = list(df[df.subclass == v.subclass].index)[0]\n",
    "        if v.subclass in qid_list:\n",
    "            df.loc[ind,'global'] += items[0][(v.subclass , v.subclass_label)]\n",
    "        else:\n",
    "            df.loc[ind,'global'] += 0\n",
    "df['global'] = round((df['global']/count_rows) * 100,2)\n",
    "for k,v in df.iterrows():\n",
    "    if v['global'] == 0:\n",
    "        ind = list(df[df.subclass == v.subclass].index)[0]\n",
    "        df.loc[ind,'global'] = '-'\n",
    "print(count_rows)\n",
    "print(count_xx)\n",
    "new_row = {'subclass_label' : 'x' , 'subclass' : 'x', 'global' :round((count_xx/count_rows) * 100,2)}\n",
    "df = df.append(pd.DataFrame.from_dict([new_row], orient='columns', dtype=None, columns=None))\n",
    "lst = [\"subclass_label\" , \"subclass\" , \"global\"]\n",
    "with pd.ExcelWriter(r'Final analytics\\new_Analytics_1.xlsx' ,  engine=\"openpyxl\" , mode  = 'a') as writer:\n",
    "    df[lst].to_excel(writer, sheet_name = 'global_analysis' , encoding='utf-8-sig' , index = False)   \n",
    "    \n",
    "for items in all_files:\n",
    "    del items[0][None]\n",
    "    df = exl_file.parse(name_dict[items[1]])\n",
    "#     print(items)\n",
    "    qid_list = list(map(lambda x :x[0] , list(items[0].keys())))\n",
    "    for k,v in df.iterrows():\n",
    "        ind = list(df[df.subclass == v.subclass].index)[0]\n",
    "        if v.subclass in qid_list:\n",
    "            df.loc[ind,'Абсолютное значение'] = items[0][(v.subclass , v.subclass_label)]\n",
    "            df.loc[ind,'Относительное значение , %'] = round(items[0][(v.subclass , v.subclass_label)]/items[2] * 100,2)\n",
    "        else:\n",
    "            df.loc[ind,'Абсолютное значение'] = '-'\n",
    "            df.loc[ind,'Относительное значение , %'] = '-'\n",
    "    new_row = {'subclass_label' : 'x' , 'subclass' : 'x', 'Встречаемость предиката для всех (%)' : '-' ,\n",
    "               'Встречаемость предиката для популярных(%)': '-' , 'Абсолютное значение' : items[3] ,\n",
    "               'Относительное значение , %' : round(items[3]* 100/items[2] , 2) }\n",
    "    df = df.append(pd.DataFrame.from_dict([new_row], orient='columns', dtype=None, columns=None))\n",
    "    for k,v in df.iterrows():\n",
    "        ind = list(df[df.subclass == v.subclass].index)[0]\n",
    "        if v['Абсолютное значение'] == 0:\n",
    "            df.loc[ind,'Абсолютное значение'] = '-'\n",
    "        if v['Относительное значение , %'] == 0:\n",
    "            df.loc[ind,'Относительное значение , %'] = '-'\n",
    "    with pd.ExcelWriter(r'Final analytics\\new_Analytics_1.xlsx' ,  engine=\"openpyxl\" , mode  = 'a') as writer:\n",
    "        df.to_excel(writer, sheet_name = items[1] , encoding='utf-8-sig' , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ua = UserAgent()\n",
    "res = []\n",
    "bad_requests = []\n",
    "\n",
    "def execute_query(qquery, entity_id):\n",
    "    sparql = SPARQLWrapper(\"https://query.wikidata.org/sparql\", agent = ua.random)\n",
    "    sparql.setQuery(qquery.format(entity_id = entity_id))\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "    return results['results']['bindings']\n",
    "\n",
    "def entities_sparqul(entity, f = 0):\n",
    "        entities = {}\n",
    "        res = []\n",
    "        s = ''\n",
    "        if f > 3:\n",
    "            global bad_requests\n",
    "            bad_requests.append(entity)\n",
    "            print('Bad request ', entity)\n",
    "            return None\n",
    "        try:\n",
    "            raw_results = execute_query(bookquery.subclass_of, entity)\n",
    "            if raw_results != []:\n",
    "                entities['entity_id'] = raw_results[0]['show']['value'].split('/')[-1]\n",
    "                entities['entity_label'] = raw_results[0]['showLabel']['value']\n",
    "                for r in raw_results:\n",
    "                    subclass = r['subclass']['value'].split('/')[-1]\n",
    "                    subclass_label = r['subclassLabel']['value']\n",
    "                    s += subclass + '_' + subclass_label + ','\n",
    "                entities['subclass'] = s\n",
    "            else:\n",
    "                raw_results = execute_query(bookquery.subclass_name, entity)\n",
    "                \n",
    "                entities['entity_id'] = raw_results[0]['show']['value'].split('/')[-1]\n",
    "                entities['entity_label'] = raw_results[0]['showLabel']['value']\n",
    "                entities['subclass'] = s\n",
    "#             print(entities)\n",
    "            res.append(entities)\n",
    "            return entities #pd.DataFrame(data = res, columns = ['entity_id', 'entity_label', 'subclass'])\n",
    "        except Exception as e:\n",
    "            time.sleep(5)\n",
    "            print(f'Exception in {entity}: {e}')\n",
    "            return entities_sparqul(entity, f + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251\n"
     ]
    }
   ],
   "source": [
    "print(len(not_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res = []\n",
    "for i in not_found:\n",
    "    if i != 'x' or i != 'х':\n",
    "        res.append(entities_sparqul(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = []\n",
    "a = []\n",
    "c = Counter()\n",
    "for i in not_found:\n",
    "    c[i] += 1 \n",
    "count = dict(c)\n",
    "for i in res:\n",
    "    if i['entity_id'] in count and not i['entity_id'] in a:\n",
    "        i['count'] = count[i['entity_id']]\n",
    "        f.append(i)\n",
    "        a.append(i['entity_id'])\n",
    "f = pd.DataFrame(data = f)\n",
    "f = f[['entity_id','entity_label','count','subclass']].sort_values(by = 'count',ascending = False)\n",
    "f.to_excel(r'Final analytics\\Other_entities_1.xlsx', sheet_name = 'by_entities' ,encoding='utf-8-sig' , index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = []\n",
    "for i in res:\n",
    "    if i['subclass'] != '':\n",
    "        a = i['subclass'].split(\",\")\n",
    "        for j in a:\n",
    "            if j != '' and not 'известная по народному названию' in j:\n",
    "                qid = j.split('_')[0]\n",
    "                label = j.split('_')[1]\n",
    "                b.append((qid, label))\n",
    "c = Counter()\n",
    "for i in b:\n",
    "    c[i] += 1 \n",
    "result = []\n",
    "for k,v in c.items():\n",
    "    dic = {}\n",
    "    dic['entity_id'] = k[0]\n",
    "    dic['subclass'] = k[1]\n",
    "    dic['count'] = v\n",
    "    result.append(dic)\n",
    "df = pd.DataFrame(data = result).sort_values(by = 'count',ascending = False)\n",
    "with pd.ExcelWriter(r'Final analytics\\Other_entities_1.xlsx' ,  engine=\"openpyxl\" , mode  = 'a') as writer:\n",
    "        df.to_excel(writer, sheet_name = 'by_subclasses' , encoding='utf-8-sig' , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = ['location_constraint' , 'sight_location']\n",
    "path = join(os.getcwd() , f'verified_files_1')\n",
    "result = []\n",
    "for file in counter_for_files(path):\n",
    "    df = pd.read_excel(file)\n",
    "    name = file.split('\\\\')[-1].split('.')[0]\n",
    "    c = Counter()\n",
    "    if  name in ones:\n",
    "        for k,v in df.iterrows():\n",
    "            c[(v['Лейбл #1 из Wikidata'] ,v['QID #1'])] += 1 \n",
    "    else:\n",
    "        for k,v in df.iterrows():\n",
    "            c[(v['Лейбл #0 из Wikidata'] ,v['QID #0'])] += 1    \n",
    "    for k,v in c.items():\n",
    "        dic = {}\n",
    "        dic['subclass_label']= k[0]\n",
    "        dic['subclass'] = k[1]\n",
    "        dic['Абсолютное значение'] = v\n",
    "        dic['Относительное значение, %'] = round(v* 100/len(df), 2)\n",
    "        result.append(dic)\n",
    "    count_x = 0\n",
    "    for_del = []\n",
    "    for i in range(len(result)):\n",
    "        if result[i]['subclass'] == 'x' or result[i]['subclass'] == 'х':\n",
    "            count_x+=result[i]['Абсолютное значение']\n",
    "            for_del.append(i)\n",
    "    for i in for_del:\n",
    "        del result[i]\n",
    "    dic = {'subclass_label' : 'не найдено' , 'subclass' : 'x' , 'Абсолютное значение' : count_x , 'Относительное значение, %' : round(count_x* 100/len(df), 2)}\n",
    "    df = pd.DataFrame(data = result).sort_values(by = 'Абсолютное значение',ascending = False)\n",
    "    df = df.append(pd.DataFrame.from_dict([dic], orient='columns', dtype=None, columns=None))\n",
    "    with pd.ExcelWriter(r'Final analytics\\new_Analytics.xlsx' ,  engine=\"openpyxl\" , mode  = 'a') as writer:\n",
    "         df.to_excel(writer, sheet_name = f'{name}_ss' , encoding='utf-8-sig' , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "exl_file = pd.ExcelFile(join(os.getcwd() , f'Final analytics\\\\Other_entities.xlsx'))\n",
    "exl_file_1 = pd.ExcelFile(join(os.getcwd() , f'Final analytics\\\\Other_entities_1.xlsx'))\n",
    "\n",
    "df = exl_file.parse('by_entities')\n",
    "df_1= exl_file_1.parse('by_entities')\n",
    "new_df = pd.concat([df, df_1])\n",
    "concat_df = new_df.groupby(['entity_id', 'entity_label']).sum().sort_values(by = 'count',ascending = False)\n",
    "concat_df.reset_index(inplace = True)\n",
    "for k,v in concat_df.iterrows():\n",
    "    ind = list(concat_df[concat_df.entity_id == v.entity_id].index)[0]\n",
    "    concat_df.loc[ind,'subclass'] = list(new_df[new_df.entity_id == v.entity_id]['subclass'])[0]\n",
    "concat_df .to_excel(r'Final analytics\\Not_found_in_our_pool.xlsx', sheet_name = 'by_entities' ,encoding='utf-8-sig' , index = False )\n",
    "\n",
    "\n",
    "df = exl_file.parse('by_subclasses')\n",
    "df_1= exl_file_1.parse('by_subclasses')\n",
    "new_df = pd.concat([df, df_1])\n",
    "new_df = new_df.groupby(['entity_id','subclass']).sum().sort_values(by = 'count',ascending = False)\n",
    "new_df.reset_index(inplace = True)\n",
    "with pd.ExcelWriter(r'Final analytics\\Not_found_in_our_pool.xlsx' ,  engine=\"openpyxl\" , mode  = 'a') as writer:\n",
    "          new_df.to_excel(writer, sheet_name = f'by_subclasses' , encoding='utf-8-sig' , index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
